# M2.5 Orchestrator Agent â€” Architecture

*Created: 2026-02-13*
*Status: Design*

## Overview

An agentic orchestrator powered by MiniMax M2.5 that autonomously manages the editorial research pipeline across 50 sites Ã— ~1000 retailers each. M2.5's strong tool calling (BFCL 76.8%) + 1/20th Opus cost makes it viable to run thousands of agent turns per batch.

**Key principle:** M2.5 handles all decision-making and coordination. Opus only for final content generation where brand voice matters.

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    M2.5 ORCHESTRATOR AGENT                       â”‚
â”‚                                                                  â”‚
â”‚  "What needs doing?" â†’ Decides â†’ Dispatches â†’ Monitors          â”‚
â”‚                                                                  â”‚
â”‚  Tools available:                                                â”‚
â”‚  â”œâ”€â”€ check_freshness(retailer, site)  â†’ last_updated, staleness â”‚
â”‚  â”œâ”€â”€ research_perplexity(retailer, query) â†’ raw facts           â”‚
â”‚  â”œâ”€â”€ research_firecrawl_agent(retailer, prompt) â†’ deep facts    â”‚
â”‚  â”œâ”€â”€ scrape_page(url) â†’ markdown content                        â”‚
â”‚  â”œâ”€â”€ verify_fact(fact, official_url) â†’ verified/outdated/wrong  â”‚
â”‚  â”œâ”€â”€ extract_facts(raw_text, retailer) â†’ structured facts[]     â”‚
â”‚  â”œâ”€â”€ embed_and_dedupe(facts[]) â†’ unique facts[]                 â”‚
â”‚  â”œâ”€â”€ compare_gaps(new_facts[], existing_content) â†’ gaps[]       â”‚
â”‚  â”œâ”€â”€ generate_content(facts, site, tone) â†’ draft [OPUS]         â”‚
â”‚  â”œâ”€â”€ submit_for_review(retailer, site, gaps, drafts) â†’ ticket   â”‚
â”‚  â””â”€â”€ log_run(retailer, stats) â†’ audit trail                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 1. Freshness Scheduler

The orchestrator's first job: **decide what needs refreshing**.

### Staleness Scoring

```typescript
interface RetailerState {
  retailer: string;
  site: string;           // e.g. "coupons.com"
  lastResearched: Date;
  lastContentUpdate: Date;
  factCount: number;
  gapCount: number;       // from last run
  priority: 'high' | 'medium' | 'low';  // based on traffic/revenue
  seasonalRelevance: number;  // 0-1, spikes around Black Friday etc.
}

// Staleness formula
function stalenessScore(state: RetailerState): number {
  const daysSinceResearch = daysBetween(state.lastResearched, now());
  const baseStaleness = Math.min(daysSinceResearch / 30, 1.0); // max at 30 days
  
  const priorityMultiplier = { high: 1.5, medium: 1.0, low: 0.5 };
  const gapPenalty = state.gapCount > 5 ? 0.2 : 0;  // pages with many gaps get refreshed sooner
  const seasonalBoost = state.seasonalRelevance;       // higher around sales events
  
  return (baseStaleness + gapPenalty + seasonalBoost) * priorityMultiplier[state.priority];
}
```

### Refresh Strategy

The orchestrator runs nightly and asks itself:

```
SYSTEM: You are the editorial research orchestrator for {site}.
You have a budget of {N} retailer refreshes per run.

Here are retailers sorted by staleness score:
{retailer_list with scores}

Recent events that may affect retailers:
- {seasonal_context: e.g. "Valentine's Day in 1 day", "Presidents Day sale week"}

TOOLS: check_freshness, research_perplexity, research_firecrawl_agent, ...

Decide which retailers to refresh and in what order. Consider:
1. Staleness score (higher = more urgent)
2. Seasonal relevance (upcoming sales events)
3. Budget constraints (cost per retailer ~$0.04)
4. Diminishing returns (don't refresh a page updated 2 days ago)
```

**Budget control:** Set daily token/cost budgets. The agent operates within them.

---

## 2. Research Strategy Selection

For each retailer, the orchestrator decides **which sources to use**:

```
DECISION TREE (M2.5 decides per retailer):

Is this a FIRST-TIME research? 
  â†’ YES: Full pipeline (Perplexity + Firecrawl Agent + verify)
  â†’ NO: Delta refresh...
  
    What changed since last run?
    â”œâ”€â”€ Seasonal event approaching â†’ Research sales calendar + promos only
    â”œâ”€â”€ Policy page URL returned 404 â†’ Re-scrape, find new URL
    â”œâ”€â”€ >30 days since full refresh â†’ Full pipeline again
    â””â”€â”€ <14 days, no events â†’ Quick Perplexity check only (~$0.01)
```

### Tool Selection Logic

```typescript
// The agent has these research tools and picks the right one:

// CHEAP + BROAD: Good for most refreshes
tools.research_perplexity(retailer, megaPrompt)  // ~$0.01

// DEEP + TARGETED: When Perplexity misses policies/discounts
tools.research_firecrawl_agent(retailer, policyPrompt)  // ~$0.02

// VERIFICATION: For high-risk facts
tools.scrape_page(officialUrl) + tools.verify_fact(fact, content)  // ~$0.003/fact

// The M2.5 orchestrator decides per retailer:
// - New retailer? â†’ Perplexity + Agent + verify all
// - Quick refresh? â†’ Perplexity only
// - Policy change suspected? â†’ Scrape specific pages
// - Sales season? â†’ Focus on promos/calendar
```

---

## 3. Fact Processing Pipeline

After research, M2.5 handles extraction and deduplication:

```
Raw research output (Perplexity markdown + Agent JSON)
        â”‚
        â–¼
  M2.5: extract_facts()          â† Structured output, JSON mode
  "Extract all facts as typed objects"
        â”‚
        â–¼
  Embed all facts (text-embedding-004, batch API)
        â”‚
        â–¼
  Dedupe (cosine similarity > 0.90 = same fact)
  Keep most detailed version
        â”‚
        â–¼
  M2.5: classify_risk()          â† Which facts need verification?
  HIGH-RISK: policies, discounts, APR â†’ verify
  LOW-RISK: sales calendar, general info â†’ trust
        â”‚
        â–¼
  For HIGH-RISK facts:
  M2.5: find_official_url() â†’ scrape_page() â†’ verify_fact()
        â”‚
        â–¼
  Final verified fact set
```

### Why M2.5 works here

Each step is a **tool call + structured output** task. No creative writing, no nuanced brand voice. Just:
- "Here's raw text, extract facts as JSON" â†’ tool calling strength
- "Here's a fact and a page, does it match?" â†’ straightforward reasoning
- "Which of these facts are high-risk?" â†’ classification

This is M2.5's sweet spot.

---

## 4. Gap Detection & Content Routing

```
Verified facts â†’ compare_gaps(facts, existing_page_content)
        â”‚
        â–¼
  Gap report:
  â”œâ”€â”€ 3 MISSING facts (not on page at all)
  â”œâ”€â”€ 2 PARTIAL facts (mentioned but incomplete/outdated)
  â””â”€â”€ 8 COVERED facts (already on page, up to date)
        â”‚
        â–¼
  M2.5 DECISION: What to do with gaps?
  â”œâ”€â”€ MISSING + HIGH-VALUE â†’ Generate new section [route to OPUS]
  â”œâ”€â”€ PARTIAL â†’ Suggest edit to existing section [route to OPUS]  
  â”œâ”€â”€ OUTDATED â†’ Flag for editor review (fact changed)
  â””â”€â”€ TRIVIAL gap â†’ Skip (not worth editor's time)
```

### Content Generation (Opus)

Only gaps that need new/updated content get routed to Opus:

```typescript
// M2.5 orchestrator calls this tool only when needed
async function generateContent(facts: Fact[], site: string, section: string) {
  // This tool internally uses OPUS for quality
  const draft = await opus.generate({
    system: `You are a content writer for ${site}. Match the site's exact tone...`,
    facts,
    section,
    examples: existingSiteContent  // for voice matching
  });
  return draft;
}
```

**Cost optimization:** Most retailers on a refresh won't have new gaps â†’ no Opus calls needed. Opus only fires for actual content changes.

---

## 5. Output & Review Queue

```typescript
interface ResearchResult {
  retailer: string;
  site: string;
  runDate: Date;
  
  // Research stats
  sourcesUsed: ('perplexity' | 'firecrawl_agent' | 'scrape')[];
  factsFound: number;
  factsVerified: number;
  
  // Gaps
  gaps: {
    type: 'missing' | 'partial' | 'outdated';
    fact: string;
    suggestedContent?: string;  // Opus-generated draft
    priority: 'high' | 'medium' | 'low';
  }[];
  
  // Cost
  cost: number;  // total for this retailer
  
  // Audit
  decisions: string[];  // log of orchestrator decisions
}
```

### Editor Interface

```
ğŸ“‹ Daily Research Digest â€” coupons.com
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Refreshed: 47 retailers | Budget used: $2.14 / $5.00
New gaps found: 12 across 8 retailers

ğŸ”´ HIGH PRIORITY (3)
â”œâ”€â”€ Dick's Sporting Goods â€” New ScoreCard Gold tier launched
â”œâ”€â”€ Target â€” Student discount dates changed for 2026  
â””â”€â”€ Best Buy â€” Trade-in values updated

ğŸŸ¡ MEDIUM (5)
â”œâ”€â”€ Walmart â€” Added Affirm BNPL option
â”œâ”€â”€ ...

ğŸŸ¢ LOW (4)
â”œâ”€â”€ ...

[Review Queue â†’]
```

---

## 6. Cost Model

### Per retailer (average)

| Step | Model | Cost |
|------|-------|------|
| Orchestrator decision (which sources, strategy) | M2.5 | ~$0.001 |
| Perplexity research | sonar-pro | ~$0.01 |
| Firecrawl Agent (when needed, ~30% of runs) | spark-1-mini | ~$0.006 avg |
| Fact extraction + classification | M2.5 | ~$0.002 |
| Embeddings (dedupe + gap detection) | text-embedding-004 | ~$0.001 |
| Verification scrapes (~5 high-risk facts) | Firecrawl + M2.5 | ~$0.015 |
| Content generation (when gaps found, ~20% of runs) | Opus | ~$0.01 avg |
| **Total per retailer** | | **~$0.04-0.05** |

### At scale

| Scenario | Retailers/day | Daily cost | Monthly |
|----------|--------------|------------|---------|
| Conservative (10% refresh) | 100 | ~$5 | ~$150 |
| Moderate (20% refresh) | 200 | ~$10 | ~$300 |
| Aggressive (full weekly) | ~700/day | ~$35 | ~$1,050 |

**Compared to Opus-only orchestration:** Same pipeline with Opus deciding everything would cost ~$50-70/day at moderate refresh. M2.5 cuts that to ~$10/day. The orchestrator agent turns are the biggest savings â€” hundreds of tool-calling decisions per batch at 1/20th the cost.

---

## 7. Seasonal Intelligence

The orchestrator should be context-aware about retail events:

```typescript
const RETAIL_CALENDAR = {
  'valentines': { start: '02-07', peak: '02-14', categories: ['gifts', 'jewelry', 'flowers'] },
  'presidents-day': { start: '02-14', peak: '02-17', categories: ['mattresses', 'appliances', 'furniture'] },
  'memorial-day': { start: '05-19', peak: '05-26', categories: ['outdoor', 'grills', 'mattresses'] },
  'prime-day': { start: '07-08', peak: '07-16', categories: ['electronics', 'amazon-competitors'] },
  'back-to-school': { start: '07-15', peak: '08-15', categories: ['clothing', 'electronics', 'office'] },
  'black-friday': { start: '11-15', peak: '11-28', categories: ['*'] },
  'cyber-monday': { start: '11-29', peak: '12-02', categories: ['electronics', 'software'] },
  // ... etc
};

// Orchestrator gets this context and prioritizes accordingly
// e.g. Feb 10: "Valentine's Day in 4 days â†’ refresh all gift/jewelry retailers"
```

---

## 8. Implementation Plan

### Phase 1: M2.5 Orchestrator Skeleton (1 week)
- [ ] Set up M2.5 via OpenRouter API
- [ ] Define tool schemas (check_freshness, research_perplexity, etc.)
- [ ] Build orchestrator loop: get stale retailers â†’ decide strategy â†’ dispatch
- [ ] Test on 10 retailers from coupons.com
- [ ] Measure cost, quality, speed vs current scripted pipeline

### Phase 2: Full Pipeline Integration (1 week)
- [ ] Connect to existing Perplexity + Firecrawl tools
- [ ] Add embeddings-based gap detection from PoC
- [ ] Add Opus content generation for gaps
- [ ] Build review queue output (JSON â†’ Slack/email digest)

### Phase 3: Scale (1 week)
- [ ] Parallelization (batch retailers, respect rate limits)
- [ ] Supabase/pgvector for persistent fact store
- [ ] Staleness tracking + refresh scheduling
- [ ] Seasonal calendar integration
- [ ] Dashboard for editors

### Phase 4: Multi-site (ongoing)
- [ ] Template per-site tone/style for Opus generation
- [ ] Site-specific fact schemas (cashback sites need different facts than coupon sites)
- [ ] Cross-site dedup (same retailer researched once, content adapted per site)

---

## Tech Stack

| Component | Tech | Why |
|-----------|------|-----|
| Orchestrator LLM | MiniMax M2.5 (via OpenRouter) | Best tool calling / cost ratio |
| Content generation | Claude Opus | Brand voice quality |
| Research (broad) | Perplexity sonar-pro | Validated, cheap, good coverage |
| Research (deep) | Firecrawl Agent (spark-1-mini) | Policy pages, official docs |
| Embeddings | Gemini text-embedding-004 | Free tier generous, good quality |
| Fact store | Supabase (pgvector) | Already in stack, SQL + vectors |
| Orchestration | Node.js + OpenRouter SDK | Simple, M2.5 tool calling |
| Scheduling | Cron or Inngest | Nightly batch runs |
| Review output | Slack digest + web UI (later) | Editors already in Slack |

---

## Key Risks

1. **M2.5 tool calling quality in practice** â€” benchmarks â‰  production. Need to test with real retailer data.
2. **Rate limits** â€” 50 sites Ã— 1000 retailers = lots of API calls. Need batching + backoff.
3. **Fact drift** â€” Perplexity sources can be stale. Verification step is critical but adds cost.
4. **Editor adoption** â€” Best system is useless if editors ignore the review queue.

---

## Related Docs

- [[editorial-research-system/README]] â€” PoC results and pipeline validation
- [[editorial-research-system/perplexity-validation-results]] â€” Cross-retailer test results
- [[editorial-research-system/firecrawl-modes-comparison]] â€” Agent vs Extract vs Scrape

